{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "mount_file_id": "1MpRbPr-y9NWbgBYT55MOHGvQXkMafDen",
      "authorship_tag": "ABX9TyOHJWP14YxoguCjdqBntCWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratheeshkumar99/Neural-machine-translation/blob/main/NMT_eng_to_hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nhHxSbC38ql"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('./drive/My Drive/Hindi_English_Truncated_Corpus .csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49kPdDKBfaDo"
      },
      "source": [
        "import tensorflow  as tf\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "# import plotly\n",
        "# import plotly.plotly as py\n",
        "# from plotly.offline import init_notebook_mode, iplot\n",
        "# plotly.offline.init_notebook_mode(connected=True)\n",
        "# import plotly.graph_objs as go"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKtxDXd-c64z",
        "outputId": "24770966-8759-4921-c9b8-8bd6c5a2d239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ...                                     hindi_sentence\n",
              "0        ted  ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
              "1        ted  ...  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
              "2  indic2012  ...   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।\n",
              "3        ted  ...     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते\n",
              "4  indic2012  ...        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCpi05JPc7_P",
        "outputId": "beef62e1-51fb-450a-f90c-818a788b93bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHzloBt2diZt"
      },
      "source": [
        "lines=pd.read_csv(\"./drive/My Drive/Hindi_English_Truncated_Corpus .csv\",encoding='utf-8')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIXqeIHedz7P",
        "outputId": "54749158-b0a9-4835-e7f2-0c3d2f8d6f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "lines['source'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DfamtJ8d2qc",
        "outputId": "77cd522a-2fa0-4dec-e14f-5d5892d5b722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "lines.head(20)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what needs to be done.</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the percentage in India.</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not paying attention.</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called Upanishad.</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tides</td>\n",
              "      <td>The then Governor of Kashmir resisted transfer , but was finally reduced to subjection with the aid of British .</td>\n",
              "      <td>कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का विरोध किया था , लेकिन अंग्रेजों की सहायता से उनकी आवाज दबा दी गयी .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>In this lies the circumstances of people before you.</td>\n",
              "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ted</td>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>“”Global Warming“” refer to warming caused in recent decades and probability of its continual presence and its indirect effect on human being.</td>\n",
              "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई वार्मिंग और इसके निरंतर बने रहने के अनुमान और इसके अप्रत्यक्ष रूप से मानव पर पड़ने वाले प्रभाव से है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tides</td>\n",
              "      <td>You may want your child to go to a school that is not run by the LEA - a non-maintained special school or an independent school that can meet your child 's needs .</td>\n",
              "      <td>हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटेन्ड ह्यबिना किसी समर्थन के हृ विशेष स्कूल , या किसी स्वतंत्र स्कूल में जाए , इजसके पास विशेष शैक्षणिक जऋऋरतों वाले बच्चों के प्रति सहूलियत हों . .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tides</td>\n",
              "      <td>Please ensure that you use the appropriate form .</td>\n",
              "      <td>कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प्रयोग कर रहें हैं .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>Category: Religious Text</td>\n",
              "      <td>श्रेणी:धर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This period summarily is pepped up with devotion.</td>\n",
              "      <td>यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ted</td>\n",
              "      <td>So there is some sort of justice</td>\n",
              "      <td>तो वहाँ न्याय है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tides</td>\n",
              "      <td>The first two were found unreliable and the prosecution case rested mainly on the evidence of the remaining five approvers .</td>\n",
              "      <td>पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों के आधार पर मुकदमा चलाया गया .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tides</td>\n",
              "      <td>They had justified their educational policy of concentrating on the education of a small number of upper and middle-class people with the argument that the new education would gradually ' filter down ' from above .</td>\n",
              "      <td>कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों तक ही अपनी शिक्षा नीति को केंद्रित करने को इस तर्क के साथ न्यायसंगत बताया कि नयी शिक्षा Zक्रमश : ऊपर से नीचे की ओर छनते हुए जायेगी .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>And now at present the naturecure, Ayurvedic and modern treatments are taking place through the government in Nepal.</td>\n",
              "      <td>हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प्राकृतिक चिकित्सा तथा आधुनिक चिकीत्सा करके सरकारी सेवा विद्यमान हे ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>Parliament time frame is 5 years and this will be dissolved before that.</td>\n",
              "      <td>लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय से पूर्व भंग किया जा सकता है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>tides</td>\n",
              "      <td>ii Register Courts , empowered to try causes for amounts not exceeding Rs 200 , when authorised by the judges .</td>\n",
              "      <td>रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्राधिकृत किए जाने पर 200 रु . तक के वादों का निर्णय करने का अधिकार था .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>Extreme weather due to increased mortality; displacements and economic loss will be compounded through growing population. Although, temperate climate has some benefits out of it such as decreased mortality due to cold weather.</td>\n",
              "      <td>बढ़ती हुई मौतों displacements और आर्थिक नुकसान जो की अतिवादी मौसम (extreme weather)के कारण संभावित हैं बढती हुई जनसँख्या (growing population)के कारण और भी बदतर हो सकते हैं . हालांकि शीतोष्ण क्षेत्र में इसके कुछ फैदे भी हो सकते हैं जैसे की ठंड की वजह से कम मौतें होना .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       source                                                                                                                                                                                                                     english_sentence                                                                                                                                                                                                                                                                hindi_sentence\n",
              "0   ted        politicians do not have permission to do what needs to be done.                                                                                                                                                                      राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .                                                                                                                                                                                                        \n",
              "1   ted        I'd like to tell you about one such child,                                                                                                                                                                                           मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                                                                                                                                                                                                                          \n",
              "2   indic2012  This percentage is even greater than the percentage in India.                                                                                                                                                                        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।                                                                                                                                                                                                                            \n",
              "3   ted        what we really mean is that they're bad at not paying attention.                                                                                                                                                                     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                                                                                                                                                                                                                              \n",
              "4   indic2012  .The ending portion of these Vedas is called Upanishad.                                                                                                                                                                              इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।                                                                                                                                                                                                                                 \n",
              "5   tides      The then Governor of Kashmir resisted transfer , but was finally reduced to subjection with the aid of British .                                                                                                                     कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का विरोध किया था , लेकिन अंग्रेजों की सहायता से उनकी आवाज दबा दी गयी .                                                                                                                                                            \n",
              "6   indic2012  In this lies the circumstances of people before you.                                                                                                                                                                                 इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।                                                                                                                                                                                                                            \n",
              "7   ted        And who are we to say, even, that they are wrong                                                                                                                                                                                     और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                                                                                                                                                                                                                            \n",
              "8   indic2012  “”Global Warming“” refer to warming caused in recent decades and probability of its continual presence and its indirect effect on human being.                                                                                       ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई वार्मिंग और इसके निरंतर बने रहने के अनुमान और इसके अप्रत्यक्ष रूप से मानव पर पड़ने वाले प्रभाव से है।                                                                                                                        \n",
              "9   tides      You may want your child to go to a school that is not run by the LEA - a non-maintained special school or an independent school that can meet your child 's needs .                                                                  हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटेन्ड ह्यबिना किसी समर्थन के हृ विशेष स्कूल , या किसी स्वतंत्र स्कूल में जाए , इजसके पास विशेष शैक्षणिक जऋऋरतों वाले बच्चों के प्रति सहूलियत हों . .                                                                            \n",
              "10  tides      Please ensure that you use the appropriate form .                                                                                                                                                                                    कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प्रयोग कर रहें हैं .                                                                                                                                                                                                           \n",
              "11  indic2012  Category: Religious Text                                                                                                                                                                                                             श्रेणी:धर्मग्रन्थ                                                                                                                                                                                                                                                           \n",
              "12  indic2012  This period summarily is pepped up with devotion.                                                                                                                                                                                    यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।                                                                                                                                                                                                                               \n",
              "13  ted        So there is some sort of justice                                                                                                                                                                                                     तो वहाँ न्याय है                                                                                                                                                                                                                                                            \n",
              "14  tides      The first two were found unreliable and the prosecution case rested mainly on the evidence of the remaining five approvers .                                                                                                         पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों के आधार पर मुकदमा चलाया गया .                                                                                                                                                                                                \n",
              "15  tides      They had justified their educational policy of concentrating on the education of a small number of upper and middle-class people with the argument that the new education would gradually ' filter down ' from above .               कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों तक ही अपनी शिक्षा नीति को केंद्रित करने को इस तर्क के साथ न्यायसंगत बताया कि नयी शिक्षा Zक्रमश : ऊपर से नीचे की ओर छनते हुए जायेगी .                                                                                         \n",
              "16  indic2012  And now at present the naturecure, Ayurvedic and modern treatments are taking place through the government in Nepal.                                                                                                                 हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प्राकृतिक चिकित्सा तथा आधुनिक चिकीत्सा करके सरकारी सेवा विद्यमान हे ।                                                                                                                                                          \n",
              "17  indic2012  Parliament time frame is 5 years and this will be dissolved before that.                                                                                                                                                             लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय से पूर्व भंग किया जा सकता है                                                                                                                                                                                                   \n",
              "18  tides      ii Register Courts , empowered to try causes for amounts not exceeding Rs 200 , when authorised by the judges .                                                                                                                      रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्राधिकृत किए जाने पर 200 रु . तक के वादों का निर्णय करने का अधिकार था .                                                                                                                                                          \n",
              "19  indic2012  Extreme weather due to increased mortality; displacements and economic loss will be compounded through growing population. Although, temperate climate has some benefits out of it such as decreased mortality due to cold weather.  बढ़ती हुई मौतों displacements और आर्थिक नुकसान जो की अतिवादी मौसम (extreme weather)के कारण संभावित हैं बढती हुई जनसँख्या (growing population)के कारण और भी बदतर हो सकते हैं . हालांकि शीतोष्ण क्षेत्र में इसके कुछ फैदे भी हो सकते हैं जैसे की ठंड की वजह से कम मौतें होना ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVDaeuE9d5PQ",
        "outputId": "fd9c23aa-2357-4eb7-a557-af9f1e12fe01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pd.isnull(lines).sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source              0\n",
              "english_sentence    2\n",
              "hindi_sentence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQu8xa98d78a"
      },
      "source": [
        "lines=lines[~pd.isnull(lines['english_sentence'])]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkAIQtnhd9m6",
        "outputId": "1a07bc58-0d55-4a26-bc30-bb01e60fd99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines.drop_duplicates(inplace=True)\n",
        "lines.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124827, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PjHpzG5d_cz",
        "outputId": "3880a151-9e24-44b5-d23f-29eeca28d6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines=lines.sample(n=124827,random_state=42)\n",
        "lines.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124827, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ3TQ8xyeBu6"
      },
      "source": [
        "# Lowercase all characters\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgHvM3GveD2_"
      },
      "source": [
        "# Remove quotes\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv0kQpvZeJnJ"
      },
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ExED5hJeMeT",
        "outputId": "f4e4ed9e-e79e-4ef7-d8bc-7b4aa9a5d1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "print(lines['english_sentence'])\n",
        "lines.shape\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25520     islam is word from arabic and it full word is salamaits definition peace surrender                                                    \n",
            "118633    everything is reliant on these computers working                                                                                      \n",
            "113495    parliament does not control the government                                                                                            \n",
            "29783     race equality new laws                                                                                                                \n",
            "111804    the provision would not affect the power of parliament to make laws in respect of income from professions etc  lrb article  rrb       \n",
            "                                                                       ...                                                                      \n",
            "122524    the judge too moved  as if to rise  but remembering the judicial convention  kept sitting                                             \n",
            "105873    ther are town corporations and remaining total  munciple corporations                                                                 \n",
            "862       the sandhara and sarvatobhadra forms are the most outstanding                                                                         \n",
            "15986     the festival has special significance for the class of farmers                                                                        \n",
            "124663    as part of your treatment some kind of photographic record may be made  for example x rays  clinical photographs or sometimes a video \n",
            "Name: english_sentence, Length: 124827, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(124827, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ep4TyXaeN9t",
        "outputId": "7b108458-83c4-4a8e-c6b0-8747a98dffd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# # Remove extra spaces\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "print(lines['english_sentence'])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25520     islam is word from arabic and it full word is salamaits definition peace surrender                                                   \n",
            "118633    everything is reliant on these computers working                                                                                     \n",
            "113495    parliament does not control the government                                                                                           \n",
            "29783     race equality new laws                                                                                                               \n",
            "111804    the provision would not affect the power of parliament to make laws in respect of income from professions etc  lrb article  rrb      \n",
            "                                                                       ...                                                                     \n",
            "122524    the judge too moved  as if to rise  but remembering the judicial convention  kept sitting                                            \n",
            "105873    ther are town corporations and remaining total  munciple corporations                                                                \n",
            "862       the sandhara and sarvatobhadra forms are the most outstanding                                                                        \n",
            "15986     the festival has special significance for the class of farmers                                                                       \n",
            "124663    as part of your treatment some kind of photographic record may be made  for example x rays  clinical photographs or sometimes a video\n",
            "Name: english_sentence, Length: 124827, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fy2Mi7KePxK"
      },
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "#print(lines['english_sentence'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lmyic5ieSgb"
      },
      "source": [
        "# Add start and end tokens to target sequences\n",
        "lines['english_sentence'] = lines['english_sentence'].apply(lambda x : '<start> '+ x + ' <end>')\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : '<start> '+ x + ' <end>')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnssGqBLeUGy",
        "outputId": "92a98273-7572-44a9-ef62-c367515bad03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25520</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; islam is word from arabic and it full word is salamaits definition peace surrender &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्द सल्लमा है जिस की दो परिभाषाएं हैं शान्ति आत्मसमर्पण। &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118633</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; everything is reliant on these computers working &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; इन कंप्यूटरों पर सब कुछ निर्भर है &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113495</th>\n",
              "      <td>tides</td>\n",
              "      <td>&lt;start&gt; parliament does not control the government &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; संसद का सरकार पपर नियंत्रण नपहीं रहता &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29783</th>\n",
              "      <td>tides</td>\n",
              "      <td>&lt;start&gt; race equality new laws &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; नये कानून नस्ली समानता &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111804</th>\n",
              "      <td>tides</td>\n",
              "      <td>&lt;start&gt; the provision would not affect the power of parliament to make laws in respect of income from professions etc lrb article rrb &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; व्यवसायों आदि से होने वाली आय के बारे में विधि बनाने की संसद की शक्ति पर उपबंध का प्रभाव नहीं पड़ेगा अनुच्छेद &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           source                                                                                                                             english_sentence                                                                                                               hindi_sentence\n",
              "25520   indic2012  <start> islam is word from arabic and it full word is salamaits definition peace surrender <end>                                             <start> इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्द सल्लमा है जिस की दो परिभाषाएं हैं शान्ति आत्मसमर्पण। <end>         \n",
              "118633  ted        <start> everything is reliant on these computers working <end>                                                                               <start> इन कंप्यूटरों पर सब कुछ निर्भर है <end>                                                                            \n",
              "113495  tides      <start> parliament does not control the government <end>                                                                                     <start> संसद का सरकार पपर नियंत्रण नपहीं रहता <end>                                                                        \n",
              "29783   tides      <start> race equality new laws <end>                                                                                                         <start> नये कानून नस्ली समानता <end>                                                                                       \n",
              "111804  tides      <start> the provision would not affect the power of parliament to make laws in respect of income from professions etc lrb article rrb <end>  <start> व्यवसायों आदि से होने वाली आय के बारे में विधि बनाने की संसद की शक्ति पर उपबंध का प्रभाव नहीं पड़ेगा अनुच्छेद <end>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYpjz8AeWE1"
      },
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in lines['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCMABqb6eX2W",
        "outputId": "59646b90-2cf8-4821-ab27-e95cea314eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(all_eng_words)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2nuwHq1eaKu",
        "outputId": "21a60dfd-54be-41fd-ff2e-cafdadcb6cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(all_hindi_words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SXqCL3oecix"
      },
      "source": [
        "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-imgdrAXeeMs",
        "outputId": "3e12ab80-beaa-40df-f989-db0ad3675d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines[lines['length_eng_sentence']>20].shape\n",
        "lines[lines['length_eng_sentence']>20].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35299, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WjcILgQegPu"
      },
      "source": [
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VM90bq0ejOa",
        "outputId": "fdccb870-afb6-438c-bae5-62cdbf5b5608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81245, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhyhQLVjDXcP",
        "outputId": "5bf814a1-6997-4297-e63d-dff5b4d0b99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>length_eng_sentence</th>\n",
              "      <th>length_hin_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118633</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; everything is reliant on these computers working &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; इन कंप्यूटरों पर सब कुछ निर्भर है &lt;end&gt;</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113495</th>\n",
              "      <td>tides</td>\n",
              "      <td>&lt;start&gt; parliament does not control the government &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; संसद का सरकार पपर नियंत्रण नपहीं रहता &lt;end&gt;</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29783</th>\n",
              "      <td>tides</td>\n",
              "      <td>&lt;start&gt; race equality new laws &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; नये कानून नस्ली समानता &lt;end&gt;</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57202</th>\n",
              "      <td>ted</td>\n",
              "      <td>&lt;start&gt; there was lasagna there was casseroles &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; वहां लाजान्या था कैसेरोल थे &lt;end&gt;</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107821</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>&lt;start&gt; super power india source google writer vedpratap vedik &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; महाशक्ति भारत गूगल पुस्तक लेखक वेदप्रताप वैदिक &lt;end&gt;</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           source                                                      english_sentence                                                hindi_sentence  length_eng_sentence  length_hin_sentence\n",
              "118633  ted        <start> everything is reliant on these computers working <end>        <start> इन कंप्यूटरों पर सब कुछ निर्भर है <end>               9                    9                  \n",
              "113495  tides      <start> parliament does not control the government <end>              <start> संसद का सरकार पपर नियंत्रण नपहीं रहता <end>           8                    9                  \n",
              "29783   tides      <start> race equality new laws <end>                                  <start> नये कानून नस्ली समानता <end>                          6                    6                  \n",
              "57202   ted        <start> there was lasagna there was casseroles <end>                  <start> वहां लाजान्या था कैसेरोल थे <end>                     8                    7                  \n",
              "107821  indic2012  <start> super power india source google writer vedpratap vedik <end>  <start> महाशक्ति भारत गूगल पुस्तक लेखक वेदप्रताप वैदिक <end>  10                   9                  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyuimzJ2ek-p"
      },
      "source": [
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU6F1HbPenAO",
        "outputId": "abfd2350-fe8b-4e90-a3e2-2673d2458169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57949, 66369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3SN39K2eovI"
      },
      "source": [
        "eng = []\n",
        "hindi = []\n",
        "for line in lines['english_sentence']:\n",
        "    eng.append(line)\n",
        "\n",
        "for line in lines['hindi_sentence']:\n",
        "    hindi.append(line)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOc7HrxLerJj"
      },
      "source": [
        "data = zip(*(eng,hindi))\n",
        "data = list(data)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJP_iKJQetM5"
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezKJFrRceuzT"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGgcIGi8ewpN"
      },
      "source": [
        "def load_dataset(pairs, num_examples):\n",
        "    # pairs => already created cleaned input, output pairs\n",
        "\n",
        "    # index language using the class defined above    \n",
        "    inp_lang = LanguageIndex(en for en, ma in pairs)\n",
        "    targ_lang = LanguageIndex(ma for en, ma in pairs)\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    # English sentences\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, ma in pairs]\n",
        "    \n",
        "    # Marathi sentences\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in ma.split(' ')] for en, ma in pairs]\n",
        "    \n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvwL1ocyezB1"
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(data, len(data))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3F-fGZe00j",
        "outputId": "340245b5-3d08-491c-85ed-ebf96a00ca28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1, random_state = 101)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66694, 66694, 7411, 7411)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D08koqT4e3Qt",
        "outputId": "9631f0ae-58d0-4a42-9c27-058da7dbeb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 128\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "print(\"English vocab_Size:\",vocab_inp_size)\n",
        "print(\"Marati vocab_Size:\",vocab_tar_size)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English vocab_Size: 50382\n",
            "Marati vocab_Size: 55818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt8o1vdze5Mt"
      },
      "source": [
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "        return tf.keras.layers.GRU(units, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True, \n",
        "                                   recurrent_activation='sigmoid', \n",
        "                                   recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg4_DS6be652"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAtJ_kQse8xE"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yxmIILFe-aH"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE) #5679,256,1024,64\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE) #13647,256,1024,64"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgHoWtiLfAlh"
      },
      "source": [
        "optimizer =tf.keras.optimizers.Adam()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2IjLqC_fDBU"
      },
      "source": [
        "checkpoint_dir = './drive/My Drive/train_C/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"check_points\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g2pIjmrfMxs",
        "outputId": "76fc188b-8d12-4dee-b414-121c0e13d7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 20\n",
        "from tqdm import tqdm \n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in (enumerate(dataset)):\n",
        "        loss = 0\n",
        "        #print(batch)\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every epoch\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.0944\n",
            "Epoch 1 Batch 100 Loss 2.6995\n",
            "Epoch 1 Batch 200 Loss 2.8925\n",
            "Epoch 1 Batch 300 Loss 2.7752\n",
            "Epoch 1 Batch 400 Loss 2.6138\n",
            "Epoch 1 Batch 500 Loss 2.5567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 1/20 [14:07<4:28:27, 847.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 2.7105\n",
            "Time taken for 1 epoch 847.7484939098358 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.2925\n",
            "Epoch 2 Batch 100 Loss 2.3194\n",
            "Epoch 2 Batch 200 Loss 2.4368\n",
            "Epoch 2 Batch 300 Loss 2.3721\n",
            "Epoch 2 Batch 400 Loss 2.3213\n",
            "Epoch 2 Batch 500 Loss 2.5575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 2/20 [28:23<4:15:01, 850.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 Loss 2.3946\n",
            "Time taken for 1 epoch 855.588223695755 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.1876\n",
            "Epoch 3 Batch 100 Loss 2.0301\n",
            "Epoch 3 Batch 200 Loss 2.1381\n",
            "Epoch 3 Batch 300 Loss 2.2585\n",
            "Epoch 3 Batch 400 Loss 2.2637\n",
            "Epoch 3 Batch 500 Loss 2.0389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 15%|█▌        | 3/20 [42:41<4:01:30, 852.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 Loss 2.1322\n",
            "Time taken for 1 epoch 857.6763687133789 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.9423\n",
            "Epoch 4 Batch 100 Loss 1.7633\n",
            "Epoch 4 Batch 200 Loss 1.5897\n",
            "Epoch 4 Batch 300 Loss 1.9002\n",
            "Epoch 4 Batch 400 Loss 1.8613\n",
            "Epoch 4 Batch 500 Loss 1.5782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 20%|██        | 4/20 [57:05<3:48:16, 856.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 Loss 1.8686\n",
            "Time taken for 1 epoch 864.5831546783447 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.5095\n",
            "Epoch 5 Batch 100 Loss 1.5502\n",
            "Epoch 5 Batch 200 Loss 1.6221\n",
            "Epoch 5 Batch 300 Loss 1.7315\n",
            "Epoch 5 Batch 400 Loss 1.6533\n",
            "Epoch 5 Batch 500 Loss 1.5837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 5/20 [1:11:34<3:34:59, 859.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 Loss 1.6224\n",
            "Time taken for 1 epoch 869.0389239788055 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.3715\n",
            "Epoch 6 Batch 100 Loss 1.4084\n",
            "Epoch 6 Batch 200 Loss 1.4948\n",
            "Epoch 6 Batch 300 Loss 1.4790\n",
            "Epoch 6 Batch 400 Loss 1.5103\n",
            "Epoch 6 Batch 500 Loss 1.4675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 30%|███       | 6/20 [1:26:11<3:21:50, 865.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 Loss 1.4011\n",
            "Time taken for 1 epoch 876.8915066719055 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.1058\n",
            "Epoch 7 Batch 100 Loss 1.1578\n",
            "Epoch 7 Batch 200 Loss 1.3274\n",
            "Epoch 7 Batch 300 Loss 1.2176\n",
            "Epoch 7 Batch 400 Loss 1.1451\n",
            "Epoch 7 Batch 500 Loss 1.1985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 35%|███▌      | 7/20 [1:40:53<3:08:31, 870.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 Loss 1.2067\n",
            "Time taken for 1 epoch 882.0015225410461 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.0463\n",
            "Epoch 8 Batch 100 Loss 0.9191\n",
            "Epoch 8 Batch 200 Loss 1.2305\n",
            "Epoch 8 Batch 300 Loss 1.2029\n",
            "Epoch 8 Batch 400 Loss 1.1603\n",
            "Epoch 8 Batch 500 Loss 1.0846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [1:55:37<2:54:52, 874.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 Loss 1.0451\n",
            "Time taken for 1 epoch 884.2553582191467 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.8188\n",
            "Epoch 9 Batch 100 Loss 1.0161\n",
            "Epoch 9 Batch 200 Loss 0.8351\n",
            "Epoch 9 Batch 300 Loss 0.9708\n",
            "Epoch 9 Batch 400 Loss 0.9180\n",
            "Epoch 9 Batch 500 Loss 0.8910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 45%|████▌     | 9/20 [2:10:19<2:40:40, 876.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 Loss 0.9136\n",
            "Time taken for 1 epoch 881.2367124557495 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.7125\n",
            "Epoch 10 Batch 100 Loss 0.7663\n",
            "Epoch 10 Batch 200 Loss 0.8829\n",
            "Epoch 10 Batch 300 Loss 0.7519\n",
            "Epoch 10 Batch 400 Loss 0.7454\n",
            "Epoch 10 Batch 500 Loss 0.9384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 10/20 [2:25:02<2:26:25, 878.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 Loss 0.8008\n",
            "Time taken for 1 epoch 883.5245373249054 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.7106\n",
            "Epoch 11 Batch 100 Loss 0.6046\n",
            "Epoch 11 Batch 200 Loss 0.7538\n",
            "Epoch 11 Batch 300 Loss 0.5905\n",
            "Epoch 11 Batch 400 Loss 0.6202\n",
            "Epoch 11 Batch 500 Loss 0.6607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 55%|█████▌    | 11/20 [2:39:37<2:11:37, 877.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11 Loss 0.7046\n",
            "Time taken for 1 epoch 875.0866425037384 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.6035\n",
            "Epoch 12 Batch 100 Loss 0.6034\n",
            "Epoch 12 Batch 200 Loss 0.6709\n",
            "Epoch 12 Batch 300 Loss 0.6108\n",
            "Epoch 12 Batch 400 Loss 0.5602\n",
            "Epoch 12 Batch 500 Loss 0.5654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 12/20 [2:54:23<1:57:18, 879.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12 Loss 0.6183\n",
            "Time taken for 1 epoch 885.3554472923279 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.5577\n",
            "Epoch 13 Batch 100 Loss 0.4912\n",
            "Epoch 13 Batch 200 Loss 0.5771\n",
            "Epoch 13 Batch 300 Loss 0.4254\n",
            "Epoch 13 Batch 400 Loss 0.5530\n",
            "Epoch 13 Batch 500 Loss 0.5695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 65%|██████▌   | 13/20 [3:09:01<1:42:36, 879.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13 Loss 0.5402\n",
            "Time taken for 1 epoch 878.7974874973297 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.4119\n",
            "Epoch 14 Batch 100 Loss 0.4131\n",
            "Epoch 14 Batch 200 Loss 0.5026\n",
            "Epoch 14 Batch 300 Loss 0.4685\n",
            "Epoch 14 Batch 400 Loss 0.4717\n",
            "Epoch 14 Batch 500 Loss 0.4938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 70%|███████   | 14/20 [3:23:13<1:27:07, 871.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14 Loss 0.4686\n",
            "Time taken for 1 epoch 851.6747484207153 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.3738\n",
            "Epoch 15 Batch 100 Loss 0.3998\n",
            "Epoch 15 Batch 200 Loss 0.4545\n",
            "Epoch 15 Batch 300 Loss 0.3675\n",
            "Epoch 15 Batch 400 Loss 0.4543\n",
            "Epoch 15 Batch 500 Loss 0.4261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 15/20 [3:37:31<1:12:15, 867.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15 Loss 0.4079\n",
            "Time taken for 1 epoch 857.751190662384 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.2986\n",
            "Epoch 16 Batch 100 Loss 0.3718\n",
            "Epoch 16 Batch 200 Loss 0.3704\n",
            "Epoch 16 Batch 300 Loss 0.3618\n",
            "Epoch 16 Batch 400 Loss 0.3819\n",
            "Epoch 16 Batch 500 Loss 0.3412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 16/20 [3:51:52<57:41, 865.49s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16 Loss 0.3513\n",
            "Time taken for 1 epoch 861.5860214233398 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.2423\n",
            "Epoch 17 Batch 100 Loss 0.2678\n",
            "Epoch 17 Batch 200 Loss 0.3478\n",
            "Epoch 17 Batch 300 Loss 0.3430\n",
            "Epoch 17 Batch 400 Loss 0.2837\n",
            "Epoch 17 Batch 500 Loss 0.3439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▌ | 17/20 [4:06:33<43:29, 869.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17 Loss 0.3294\n",
            "Time taken for 1 epoch 880.14794921875 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.2520\n",
            "Epoch 18 Batch 100 Loss 0.3613\n",
            "Epoch 18 Batch 200 Loss 0.3380\n",
            "Epoch 18 Batch 300 Loss 0.3295\n",
            "Epoch 18 Batch 400 Loss 0.2639\n",
            "Epoch 18 Batch 500 Loss 0.3444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 18/20 [4:21:15<29:07, 873.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18 Loss 0.2942\n",
            "Time taken for 1 epoch 882.5060198307037 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.2088\n",
            "Epoch 19 Batch 100 Loss 0.2004\n",
            "Epoch 19 Batch 200 Loss 0.1945\n",
            "Epoch 19 Batch 300 Loss 0.2472\n",
            "Epoch 19 Batch 400 Loss 0.1867\n",
            "Epoch 19 Batch 500 Loss 0.2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 19/20 [4:35:59<14:36, 876.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19 Loss 0.2222\n",
            "Time taken for 1 epoch 884.1838736534119 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.1665\n",
            "Epoch 20 Batch 100 Loss 0.1444\n",
            "Epoch 20 Batch 200 Loss 0.1753\n",
            "Epoch 20 Batch 300 Loss 0.1904\n",
            "Epoch 20 Batch 400 Loss 0.2001\n",
            "Epoch 20 Batch 500 Loss 0.2270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [4:50:37<00:00, 871.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20 Loss 0.1800\n",
            "Time taken for 1 epoch 877.3177452087402 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBmf6NRDfXXb",
        "outputId": "201eebc1-b641-43f0-be5c-912ef955190e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint('./drive/My Drive/train_C/'))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9e5818ab38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8I15vQNjhgy"
      },
      "source": [
        "def evaluate(inputs, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    \n",
        "    #attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = ''\n",
        "    for i in inputs[0]:\n",
        "        if i == 0:\n",
        "            break\n",
        "        sentence = sentence + inp_lang.idx2word[i] + ' '  # GEtting out the actual sentence from the indexed representation\n",
        "    sentence = sentence[:-1]    # removing the end token\n",
        "    inputs = tf.convert_to_tensor(inputs) #converting the list into a tensor to fed into the model\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]  #initialising the hidden-states of the encoder\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden) #feeding the input and hidden states to the encoder\n",
        "\n",
        "    dec_hidden = enc_hidden  #initialising the  decoder's hidden state as the encoder's output\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0) #hard-coding the first time step decoder input ad start token as expanding its dims so as to include batch size since the model accepts batch_size of imputs\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "      \n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out) #The decoder return the ouput of that time step as-well as the hidden states(to be fed into the attention mechganism for the next time step) and attention weights\n",
        "        \n",
        "        # storing the attention weights to plot later on\n",
        "        #attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        #attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "        #print(result)\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>': #stop the decoder loop if end token is emitted \n",
        "            return result, sentence\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnhnisp32E4o"
      },
      "source": [
        "def predict_random_val_sentence():\n",
        "    actual_sent = ''\n",
        "    k = np.random.randint(len(input_tensor_val))\n",
        "    random_input = input_tensor_val[k]\n",
        "    random_output = target_tensor_val[k]\n",
        "    random_input = np.expand_dims(random_input,0)\n",
        "    result, sentence = evaluate(random_input, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    print(sentence)\n",
        "    print(result)\n",
        "    print('Input: {}'.format(sentence[8:-6]))\n",
        "    print('Predicted translation: {}'.format(result[:-6]))\n",
        "    for i in random_output:\n",
        "        if i == 0:\n",
        "            break\n",
        "        actual_sent = actual_sent + targ_lang.idx2word[i] + ' '\n",
        "    actual_sent = actual_sent[8:-7]\n",
        "    print('Actual translation: {}'.format(actual_sent))\n",
        "    #attention_plot = attention_plot[:len(result.split(' '))-2, 1:len(sentence.split(' '))-1]\n",
        "    sentence, result = sentence.split(' '), result.split(' ')\n",
        "    sentence = sentence[1:-1]\n",
        "    result = result[:-2]\n",
        "    \n",
        "    # # use plotly to generate the heat map\n",
        "    # trace = go.Heatmap(z = attention_plot, x = sentence, y = result, colorscale='Reds')\n",
        "    # data=[trace]\n",
        "    # iplot(data)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPLVX3xm2dUV",
        "outputId": "ea0ba11a-e3fa-4d92-bd4f-3654aa19d810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "predict_random_val_sentence()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> pandava kunthi and madhuri are all in pandus <end>\n",
            "तौरात और पाण्डु के मध्य में सभी बहुमूल्य पत्थरों का पूर्ण हैं। <end> \n",
            "Input: pandava kunthi and madhuri are all in pandus\n",
            "Predicted translation: तौरात और पाण्डु के मध्य में सभी बहुमूल्य पत्थरों का पूर्ण हैं। \n",
            "Actual translation: पाण्डव पाण्डु की कुन्ती और माद्री से सन्ताने।\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joaLaogi2gDz"
      },
      "source": [
        ""
      ],
      "execution_count": 122,
      "outputs": []
    }
  ]
}